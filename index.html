<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Selfie Uploader</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://telegram.org/js/telegram-web-app.js"></script>
<style>
  body { font-family: system-ui, sans-serif; padding: 16px; }
  #preview { margin-top: 16px; max-width: 100%; border-radius: 12px; }
  button, input { margin-top: 12px; width: 100%; padding: 12px; border-radius: 10px; }
  #gallery { display: grid; grid-template-columns: repeat(3, 1fr); gap: 8px; margin-top: 16px; }
  #gallery img { width: 100%; aspect-ratio: 1 / 1; object-fit: cover; border-radius: 10px; }
</style>
  </head>
  <body>
    <h3>Upload your selfie</h3>
    <input id="file" type="file" accept="image/*" />
    <button id="uploadBtn">Upload</button>

    <img id="preview" alt="Preview will appear here" />
    <div id="gallery"></div>

    <script>
  const BACKEND_BASE = "https://newfoundland-administered-peoples-limiting.trycloudflare.com"; // change
  const tg = window.Telegram.WebApp; tg.ready();

  async function requestPresign(file) {
    const initData = tg.initData || "";
    const res = await fetch(`${BACKEND_BASE}/selfies/presign-upload`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ initData, filename: file.name, contentType: file.type })
    });
    if (!res.ok) throw new Error("Failed to presign");
    return res.json(); // { uploadUrl, key }
  }

  async function finalize({ key, sizeBytes, contentType }) {
    const initData = tg.initData || "";
    const res = await fetch(`${BACKEND_BASE}/selfies/finalize`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ initData, key, sizeBytes, contentType })
    });
    if (!res.ok) throw new Error("Failed to finalize");
    return res.json(); // { previewUrl, gallery:[{key,url}] }
  }

  async function loadGallery(limit = 24) {
    const initData = tg.initData || "";
    const res = await fetch(`${BACKEND_BASE}/selfies/list`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ initData, limit })
    });
    if (!res.ok) throw new Error("Failed to load gallery");
    const items = await res.json(); // [{key, url}]
    renderGallery(items);
  }

   // call on startup
  document.addEventListener("DOMContentLoaded", () => {
    loadGallery().catch(err => console.error(err));
  });

  function renderGallery(items) {
    const wrap = document.getElementById("gallery");
    wrap.innerHTML = "";
    items.forEach(it => {
      const img = document.createElement("img");
      img.src = it.url;
      img.alt = it.key;
      wrap.appendChild(img);
    });
  }

    document.getElementById("uploadBtn").onclick = async () => {
    const original = document.getElementById("file").files[0];
    if (!original) { alert("Pick a file first"); return; }

    try {
      // 1) Compress to <= 1.5 MB
      const file = await compressImageToLimit(original, 1_500_000, 2048);

      // 2) Presign using the NEW name and type (likely .jpg / image/jpeg)
      const { uploadUrl, key } = await requestPresign(file);

      // 3) Upload compressed blob (SSE still required by your bucket policy)
      const putRes = await fetch(uploadUrl, {
        method: "PUT",
        headers: {
          "Content-Type": file.type,
          "x-amz-server-side-encryption": "AES256"
        },
        body: file
      });
      if (!putRes.ok) throw new Error("Upload failed");

      // 4) Finalize with the compressed size/type
      const { previewUrl, gallery } = await finalize({
        key, sizeBytes: file.size, contentType: file.type
      });

      document.getElementById("preview").src = previewUrl;
      renderGallery(gallery || []);
      tg.HapticFeedback?.notificationOccurred("success");
    } catch (e) {
      alert(e.message);
      tg.HapticFeedback?.notificationOccurred("error");
    }
  };
</script>
<script>
  const MAX_BYTES = 1_500_000; // 1.5 MB
  const MAX_DIM   = 2048;      // optional: downscale large images

  // Read a File/Blob into an ImageBitmap (fast) or HTMLImageElement fallback
  async function fileToBitmap(file) {
    if ('createImageBitmap' in window) {
      const bitmap = await createImageBitmap(file);
      return { img: bitmap, w: bitmap.width, h: bitmap.height, close: () => bitmap.close() };
    }
    // Fallback for old webviews
    const url = URL.createObjectURL(file);
    const img = new Image();
    await new Promise((res, rej) => { img.onload = res; img.onerror = rej; img.src = url; });
    URL.revokeObjectURL(url);
    return { img, w: img.naturalWidth, h: img.naturalHeight, close: () => {} };
  }

  // Draw image into a canvas with optional downscale to MAX_DIM
  function drawToCanvas(source, targetW, targetH) {
    const canvas = document.createElement('canvas');
    canvas.width = targetW;
    canvas.height = targetH;
    const ctx = canvas.getContext('2d');
    // better quality scaling on some devices
    ctx.imageSmoothingEnabled = true;
    ctx.imageSmoothingQuality = 'high';
    ctx.drawImage(source, 0, 0, targetW, targetH);
    return canvas;
  }

  // Binary search JPEG quality to fit under MAX_BYTES (with a safety margin)
  async function canvasToJpegUnder(canvas, maxBytes = MAX_BYTES) {
    let lo = 0.5, hi = 0.95, bestBlob = null;

    // Try high quality first
    let blob = await new Promise(r => canvas.toBlob(r, 'image/jpeg', hi));
    if (!blob) throw new Error("Canvas export failed");
    if (blob.size <= maxBytes) return blob;

    // Then binary search quality
    for (let i = 0; i < 7; i++) { // ~7 iterations is enough
      const mid = (lo + hi) / 2;
      blob = await new Promise(r => canvas.toBlob(r, 'image/jpeg', mid));
      if (!blob) throw new Error("Canvas export failed");
      if (blob.size <= maxBytes) {
        bestBlob = blob; hi = mid;
      } else {
        lo = mid;
      }
    }
    if (bestBlob) return bestBlob;

    // If even q=0.5 is too big, weâ€™ll return that (will still be > max)
    return blob;
  }

  // Main compression function: optional downscale + quality search
  async function compressImageToLimit(file, maxBytes = MAX_BYTES, maxDim = MAX_DIM) {
    const { img, w, h, close } = await fileToBitmap(file);
    try {
      // compute target size within maxDim
      let tw = w, th = h;
      const scale = Math.max(w, h) > maxDim ? maxDim / Math.max(w, h) : 1;
      if (scale < 1) { tw = Math.round(w * scale); th = Math.round(h * scale); }

      const canvas = drawToCanvas(img, tw, th);
      let jpegBlob = await canvasToJpegUnder(canvas, maxBytes);

      // If still too big, progressively shrink dimensions and retry
      let attempts = 0;
      while (jpegBlob.size > maxBytes && attempts < 3 && Math.max(tw, th) > 512) {
        tw = Math.round(tw * 0.85);
        th = Math.round(th * 0.85);
        const c2 = drawToCanvas(img, tw, th);
        jpegBlob = await canvasToJpegUnder(c2, maxBytes);
        attempts++;
      }
      return new File([jpegBlob], replaceExt(file.name, '.jpg'), { type: 'image/jpeg' });
    } finally {
      close();
    }
  }

  function replaceExt(name, newExt) {
    const i = name.lastIndexOf('.');
    return (i > 0 ? name.slice(0, i) : name) + newExt;
  }
</script>
  </body>
</html>
